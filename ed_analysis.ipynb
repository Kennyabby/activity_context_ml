{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "54a14a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, Normalizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "02c6eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads data from file path specified in the parameter.\n",
    "def read_data(path):\n",
    "#    initialized error as false\n",
    "    error = False\n",
    "    try:\n",
    "#       read file from path\n",
    "        pd_data = pd.read_csv(path)\n",
    "        \n",
    "    except IOError as err:\n",
    "        print('Could not find file path',path+'.')\n",
    "        # set error to be true\n",
    "        error = True\n",
    "    finally:\n",
    "        # if error is false return pd_data\n",
    "        if not error:\n",
    "            return pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb3f95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs data cleaning. \"data\" must be a pandas type parameter\n",
    "def clean_data(data, drop_list=[]):\n",
    "    \n",
    "    drop_data = data\n",
    "    \n",
    "    # drops the features in the drop_list parameter.\n",
    "    if len(drop_list)!= 0:        \n",
    "        drop_data = data.drop(drop_list, axis = 1)\n",
    "        \n",
    "    # This drops the all rows that contain Null values.\n",
    "    cleaned_data = drop_data.dropna()\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd73ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into its target and features\n",
    "class DataFeaturizer:\n",
    "    # \"data\" type: pandas object\n",
    "    def __init__ (self, data):\n",
    "        self.data = data\n",
    "        self.features = []\n",
    "        self.processed_features = []        \n",
    "        self.target = []\n",
    "    \n",
    "    '''set_features: extracts the features and target of the data (pandas type) provided.\n",
    "        parameters: (column (target column): 'string', encode_target (LabelEncoder): 'boolean', \n",
    "        feature_processor(sklearn.preprocessing):'string' ['standard_scalar', 'normalizer'] )\n",
    "    '''\n",
    "    def set_features (self, column, encode_target=False, feature_processor=''):\n",
    "        feature_processors = ['standard_scalar', 'normalizer', '']\n",
    "        target = self.data[column]\n",
    "        features = self.data.drop(column, axis=1)\n",
    "        if feature_processor == 'standard_scalar':\n",
    "            scaler = StandardScaler()\n",
    "            self.processed_features = scaler.fit_transform(features)\n",
    "        elif feature_processor == 'normalizer':\n",
    "            normalizer = Normalizer()\n",
    "            self.processed_features = normalizer.fit_transform(features)\n",
    "        elif feature_processor not in feature_processors:\n",
    "            print('class DataFeaturizer does not have the processor requested. Pick from the following list:',feature_processors[0:2])\n",
    "        self.features = features\n",
    "        \n",
    "        if encode_target:\n",
    "            encoder = LabelEncoder()\n",
    "            self.target = encoder.fit_transform(target)\n",
    "        else:\n",
    "            self.target = target\n",
    "    \n",
    "    '''get_features: returns features as a pandas type variable.'''\n",
    "    def get_features(self):\n",
    "        features = self.features\n",
    "        if len(features)!=0:\n",
    "            return features\n",
    "        else:\n",
    "            print('feature is currently an empty list. Initialize feature with set_features method.')\n",
    "            return []\n",
    "    '''get_processed_features: returns procces_features as an array type variable.'''\n",
    "    def get_processed_features(self):\n",
    "        processed_features = self.processed_features\n",
    "        if len(processed_features)!=0:\n",
    "            return processed_features\n",
    "        else:\n",
    "            print('processed_feature is currently an empty list. Pass feature_processor parameter in the set_features method.')\n",
    "            return []\n",
    "    '''get_target: returns target as a pandas type variable.'''\n",
    "    def get_target(self):\n",
    "        target = self.target\n",
    "        if len(target)!=0:\n",
    "            return self.target\n",
    "        else:\n",
    "            print('target is currently an empty list. Initialize target with set_features method.')\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "618ecbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts statistical features from raw features\n",
    "class FeatureExtractor:\n",
    "    def __init__ (self, feature_array):\n",
    "        self.feature_array = feature_array        \n",
    "        self.stats_dict = {}        \n",
    "        self.feature_matrix = []\n",
    "    \n",
    "    # Extracts mean feature\n",
    "    def set_mean(self):\n",
    "        mean = np.mean(self.feature_array, axis = 1, keepdims=True)\n",
    "        self.mean = mean\n",
    "    def get_mean(self):\n",
    "        return self.mean\n",
    "    \n",
    "    # Extracts median feature\n",
    "    def set_median(self):\n",
    "        median = np.median(self.feature_array, axis = 1, keepdims=True)\n",
    "        self.median = median\n",
    "    def get_median(self):\n",
    "        return self.median\n",
    "    \n",
    "    # Extracts variance feature\n",
    "    def set_variance(self):\n",
    "        variance = np.var(self.feature_array, axis = 1, keepdims = True)\n",
    "        self.variance = variance\n",
    "    def get_variance(self):\n",
    "        return self.variance\n",
    "    \n",
    "    # Extracts standard deviation feature\n",
    "    def set_std_dev(self):\n",
    "        std_dev = np.std(self.feature_array, axis = 1, keepdims = True)\n",
    "        self.std_dev = std_dev\n",
    "    def get_std_dev(self):\n",
    "        return self.std_dev\n",
    "    \n",
    "    # Extracts sum of squres (sos) feature\n",
    "    def set_sos(self):\n",
    "        sos = np.sum((self.feature_array - self.mean) ** 2, axis = 1, keepdims = True)\n",
    "        self.sos = sos\n",
    "    def get_sos(self):\n",
    "        return self.sos\n",
    "    \n",
    "    # Extracts root mean square (rms) feature\n",
    "    def set_rms(self):\n",
    "        rms = np.sqrt(np.mean(self.feature_array ** 2, axis = 1, keepdims=True))\n",
    "        self.rms = rms\n",
    "    def get_rms(self):\n",
    "        return self.rms\n",
    "    \n",
    "    # Extracts zero-crossing feature\n",
    "    def set_zero_crossing(self):\n",
    "        zero_crossing = (np.sum(np.abs(np.diff(np.sign(self.feature_array))), axis = 1, keepdims=True)/self.feature_array.shape[1])\n",
    "        self.zero_crossing = zero_crossing\n",
    "    def get_zero_crossing(self):\n",
    "        return self.zero_crossing\n",
    "    \n",
    "    # Initializes the statistical features extraction\n",
    "    def set_stats(self, pre=''):\n",
    "        self.set_mean()\n",
    "        self.set_median()\n",
    "        self.set_variance()\n",
    "        self.set_std_dev()\n",
    "        self.set_sos()\n",
    "        self.set_rms()\n",
    "        self.set_zero_crossing()\n",
    "        \n",
    "        features_label = ['mean', 'median', 'std_dev', 'variance', 'sos', 'rms', 'zero_crossing']\n",
    "        extracted_features = [self.mean, self.median, self.std_dev, self.variance, self.sos, self.rms, self.zero_crossing]\n",
    "        stats_dict ={}\n",
    "        for i in range(len(features_label)):\n",
    "            stats_dict[pre+features_label[i]] = extracted_features[i]\n",
    "        self.stats_dict = stats_dict\n",
    "    def get_stats(self):\n",
    "        return self.stats_dict\n",
    "    \n",
    "    # Combines all features into an array\n",
    "    def set_feature_matrix(self):\n",
    "        feature_matrix = np.concatenate(tuple(list(self.stats_dict.values())), axis = 1)\n",
    "        self.feature_matrix = feature_matrix\n",
    "    def get_feature_matrix(self):\n",
    "        self.set_feature_matrix()\n",
    "        return self.feature_matrix\n",
    "    \n",
    "    # Coverts the feature_matrix into a Dataframe\n",
    "    def get_feature_df(self):\n",
    "        self.set_feature_matrix()\n",
    "        feature_df = pd.DataFrame(self.feature_matrix, columns = list(self.stats_dict.keys()))\n",
    "        return feature_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "01a21ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects best features that is suitable for model input.\n",
    "class FeatureSelector:\n",
    "    def __init__ (self, feature_matrix, target, stats_dict={}):\n",
    "        self.feature_matrix = feature_matrix\n",
    "        self.target = target\n",
    "        self.stats_dict = stats_dict\n",
    "        self.mi_dict = {}\n",
    "    \n",
    "    # Computes mutual information scores\n",
    "    def set_mi_scores(self):\n",
    "        mi_scores = mutual_info_classif(self.feature_matrix, self.target)\n",
    "        mi_dict = {}\n",
    "        for i, score in enumerate(mi_scores):\n",
    "            mi_dict[list(self.stats_dict.keys())[i]] = f\"{score:.3f}\" \n",
    "        self.mi_dict = mi_dict\n",
    "    def get_mi_scores(self):\n",
    "        self.set_mi_scores()\n",
    "        return self.mi_dict\n",
    "    \n",
    "    # Selects Best Features using mutual_info_classif\n",
    "    def get_selected_features(self, k):\n",
    "        # Selects top k features with highest mutual information\n",
    "        selector = SelectKBest(mutual_info_classif, k=k)\n",
    "        new_features = selector.fit_transform(self.feature_matrix, self.target)\n",
    "        \n",
    "        # Gets the indices of the selected features\n",
    "        selected_indices = selector.get_support(indices=True)\n",
    "        \n",
    "        # Creates a new table with only the selected features\n",
    "        selected_features = []\n",
    "        for i in selected_indices:\n",
    "            selected_features += [list(self.stats_dict.keys())[i]]\n",
    "        return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc1a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
